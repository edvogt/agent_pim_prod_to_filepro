#!/usr/bin/env python3
# ============================================================================
#  stimport — Data Import Utility for EAR Product Database
#  Version: 1.3.1
#  Imports tab-delimited TSV files into FilePro database
# ============================================================================
import os
import sys
import subprocess
import argparse
import re
import shutil
import glob

# Configuration
FPMERGE_DIR = "/appl/fpmerge"
STIMPORT_TXT = f"{FPMERGE_DIR}/stimport.txt"
STIMPORT_RAW = f"{FPMERGE_DIR}/stimport-raw.txt"
STIMPORT_UTF = f"{FPMERGE_DIR}/stimport-UTF.txt"
FP_DIR = os.environ.get("FP", "/appl/fp")

DRY_RUN = False

def check_user():
    """Ensure script is run as filepro user."""
    logname = os.environ.get("LOGNAME", "")
    if logname != "filepro":
        print("Run as filepro user only, quitting...")
        sys.exit(1)

def setup_permissions():
    """Setup working files by clearing them."""
    for filepath in [STIMPORT_TXT, STIMPORT_RAW]:
        if DRY_RUN:
            print(f"[DRY-RUN] Would clear: {filepath}")
        else:
            try:
                os.makedirs(os.path.dirname(filepath), exist_ok=True)
                open(filepath, 'w').close()
            except (PermissionError, OSError) as e:
                print(f"Warning: Could not clear {filepath}: {e}")

def show_banner():
    """Display the application banner."""
    print("""
Data import utility for EAR product database

Usage:
    stimport <file.tsv>    Import an existing TSV file
    stimport <PREFIX>      Export from Pimcore using 3-char prefix, then import
                           Example: stimport BRD

""")

def validate_import_file(filepath):
    """Check if import file exists and is readable."""
    if not filepath:
        return False
    if not os.path.isfile(filepath):
        return False
    if not os.access(filepath, os.R_OK):
        return False
    return True

def clean_import_file(importfile):
    """
    Clean the import file:
    - Remove empty lines
    - Remove comment lines (starting with # or containing "#)
    - Remove special characters
    - Convert to UTF-8
    - Fix formatting
    """
    # In dry-run mode with non-existent file, simulate the cleaning
    if DRY_RUN and not os.path.exists(importfile):
        print(f"[DRY-RUN] Would clean import file: {importfile}")
        print(f"[DRY-RUN] Would write to: {STIMPORT_RAW}")
        print(f"[DRY-RUN] Would run: iconv -f UTF-8 {STIMPORT_RAW} -c -o {STIMPORT_UTF}")
        print(f"[DRY-RUN] Would write formatted output to: {STIMPORT_TXT}")
        return True

    # Read and filter the file
    with open(importfile, 'r', encoding='utf-8', errors='ignore') as f:
        lines = f.readlines()

    cleaned_lines = []
    for line in lines:
        # Skip empty lines
        if not line.strip():
            continue
        # Skip lines starting with # or containing "#
        if line.startswith('#') or '"#' in line:
            continue

        # Remove special characters (equivalent to tr -d commands)
        # Characters: \224, \226, ", \231, \274, \276, \201-\370
        line = line.replace('"', '')
        # Remove other special characters by keeping only printable ASCII + tabs
        line = re.sub(r'[^\x09\x0a\x20-\x7e]', '', line)

        cleaned_lines.append(line)

    if DRY_RUN:
        print(f"[DRY-RUN] Cleaned {len(cleaned_lines)} lines from {importfile}")
        print(f"[DRY-RUN] Would write to: {STIMPORT_RAW}")
        print(f"[DRY-RUN] Would run: iconv -f UTF-8 {STIMPORT_RAW} -c -o {STIMPORT_UTF}")
        print(f"[DRY-RUN] Would write formatted output to: {STIMPORT_TXT}")
        # Show sample of cleaned data
        if cleaned_lines:
            print(f"[DRY-RUN] Sample (first 3 lines):")
            for line in cleaned_lines[:3]:
                print(f"  {line.strip()[:80]}...")
        return True

    # Write raw cleaned file
    with open(STIMPORT_RAW, 'w', encoding='utf-8') as f:
        f.writelines(cleaned_lines)

    # Convert to UTF-8 (already UTF-8, but run iconv equivalent)
    subprocess.run([
        'iconv', '-f', 'UTF-8', STIMPORT_RAW, '-c', '-o', STIMPORT_UTF
    ], capture_output=True)

    # Final formatting with sed equivalent
    with open(STIMPORT_UTF, 'r', encoding='utf-8', errors='ignore') as f:
        content = f.read()

    # Apply sed transformations:
    # s/.$/\t/  - replace last char with tab
    # s/\t /\t/ - remove space after tab
    # s/^ //    - remove leading space
    # s/  / /g  - collapse double spaces

    formatted_lines = []
    for line in content.split('\n'):
        if line:
            # Replace last char with tab (if line has content)
            if len(line) > 0:
                line = line[:-1] + '\t' if line else line
            # Remove space after tab
            line = line.replace('\t ', '\t')
            # Remove leading space
            line = line.lstrip(' ')
            # Collapse double spaces
            while '  ' in line:
                line = line.replace('  ', ' ')
            formatted_lines.append(line)

    # Write final file
    with open(STIMPORT_TXT, 'w', encoding='utf-8') as f:
        f.write('\n'.join(formatted_lines))

    return True

def run_import():
    """Run the FilePro import process."""
    dreport_cmd = f"{FP_DIR}/dreport"
    cmd = [
        dreport_cmd, 'sel', '-f', 'tabimport', '-u',
        '-Y', 'bogus', '-s', 'rec5', '-p', '/dev/null'
    ]

    if DRY_RUN:
        print(f"[DRY-RUN] Would run: {' '.join(cmd)}")
        return True

    result = subprocess.run(cmd, capture_output=False)
    return result.returncode == 0

def export_from_pimcore(prefix):
    """
    Export products from Pimcore using 0_main.py with the given prefix.

    Args:
        prefix: 3-character PartPrefix to filter products

    Returns:
        Path to the generated TSV file, or None if export failed
    """
    script_dir = os.path.dirname(os.path.abspath(__file__))
    main_script = os.path.join(script_dir, "0_main.py")
    venv_python = os.path.join(script_dir, "venv", "bin", "python")

    if not os.path.exists(main_script):
        print(f"Error: {main_script} not found")
        return None

    # Use venv Python if available, otherwise fall back to sys.executable
    python_exe = venv_python if os.path.exists(venv_python) else sys.executable

    print(f"Exporting products from Pimcore with prefix '{prefix}'...")

    # Get list of TSV files before export
    export_dir = os.path.join(script_dir, "exports")
    tsv_pattern = os.path.join(export_dir, f"{prefix}-pimcore-export-*.tsv")
    existing_files = set(glob.glob(tsv_pattern))

    if DRY_RUN:
        print(f"[DRY-RUN] Would run: {python_exe} {main_script} --prefix {prefix} --max 10000")
        # Return a fake filename for dry-run
        return f"{prefix}-pimcore-export-DRYRUN.tsv"

    # Run 0_main.py to export products (no limit on items)
    try:
        result = subprocess.run(
            [python_exe, main_script, "--prefix", prefix, "--max", "10000"],
            capture_output=True,
            text=True,
            cwd=script_dir
        )

        if result.returncode != 0:
            print(f"Error exporting from Pimcore:")
            print(result.stderr)
            return None

        # Print output from export
        if result.stdout:
            print(result.stdout)

    except Exception as e:
        print(f"Error running export: {e}")
        return None

    # Find the newly created TSV file
    new_files = set(glob.glob(tsv_pattern)) - existing_files

    if not new_files:
        # Check if any TSV was created (might have different naming)
        all_tsv = glob.glob(os.path.join(export_dir, "*.tsv"))
        all_tsv.sort(key=lambda x: os.path.getmtime(x), reverse=True)
        if all_tsv:
            newest = all_tsv[0]
            # Check if it was created in the last minute
            import time
            if time.time() - os.path.getmtime(newest) < 60:
                print(f"Created: {os.path.basename(newest)}")
                return newest

        print("Warning: No new TSV file was created")
        return None

    # Return the newest file created
    new_file = max(new_files, key=lambda x: os.path.getmtime(x))
    print(f"Created: {os.path.basename(new_file)}")
    return new_file

def archive_old_tsv_files(archive_dir="archive", keep_recent=5):
    """
    Move old TSV files to archive directory, keeping the most recent ones.

    Args:
        archive_dir: Directory to move old files to
        keep_recent: Number of most recent TSV files to keep
    """
    # Get exports directory (where TSV files are located)
    script_dir = os.path.dirname(os.path.abspath(__file__))
    export_dir = os.path.join(script_dir, "exports")
    archive_path = os.path.join(export_dir, archive_dir)

    # Find all TSV files in exports directory
    tsv_pattern = os.path.join(export_dir, "*.tsv")
    tsv_files = glob.glob(tsv_pattern)

    if not tsv_files:
        print("No TSV files found to archive.")
        return

    # Sort by modification time (newest first)
    tsv_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)

    # Files to archive (all except the most recent ones)
    files_to_archive = tsv_files[keep_recent:]

    if not files_to_archive:
        print(f"Only {len(tsv_files)} TSV file(s) found, nothing to archive.")
        return

    # Create archive directory if it doesn't exist
    if DRY_RUN:
        if not os.path.exists(archive_path):
            print(f"[DRY-RUN] Would create directory: {archive_path}")
    else:
        os.makedirs(archive_path, exist_ok=True)

    # Move files to archive
    moved_count = 0
    for filepath in files_to_archive:
        filename = os.path.basename(filepath)
        dest_path = os.path.join(archive_path, filename)

        if DRY_RUN:
            print(f"[DRY-RUN] Would move: {filename} -> {archive_dir}/")
        else:
            try:
                shutil.move(filepath, dest_path)
                moved_count += 1
            except Exception as e:
                print(f"Error moving {filename}: {e}")

    if DRY_RUN:
        print(f"[DRY-RUN] Would archive {len(files_to_archive)} TSV file(s), keeping {keep_recent} most recent")
    else:
        print(f"Archived {moved_count} TSV file(s) to {archive_dir}/, kept {keep_recent} most recent")

def main():
    parser = argparse.ArgumentParser(
        description="Data import utility for EAR product database"
    )
    parser.add_argument(
        'importfile',
        nargs='?',
        help="Path to TSV file to import, OR a 3-character prefix to export from Pimcore first"
    )
    parser.add_argument(
        '--skip-user-check',
        action='store_true',
        help="Skip the filepro user check (for testing)"
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help="Simulate import without executing FilePro commands"
    )
    args = parser.parse_args()

    # Set dry-run mode
    global DRY_RUN
    DRY_RUN = args.dry_run

    # Check user (unless skipped for testing)
    if not args.skip_user_check:
        check_user()

    show_banner()

    # Setup working files
    setup_permissions()

    # Get import file
    importfile = args.importfile
    if not importfile:
        importfile = input("Enter the name of IMPORT FILE (or 3-char prefix): ").strip()

    # Check if argument is a 3-character prefix (export from Pimcore first)
    exported_from_pimcore = False
    if importfile and len(importfile) == 3 and importfile.isalpha():
        prefix = importfile.upper()
        print(f"Detected 3-character prefix: {prefix}")
        print("Will export from Pimcore first, then import...")
        print()

        tsv_file = export_from_pimcore(prefix)
        if tsv_file:
            importfile = tsv_file
            exported_from_pimcore = True
        else:
            print("Export failed, cannot proceed with import")
            sys.exit(1)

    # Update permissions on import file
    if importfile and not DRY_RUN:
        subprocess.run(['sudo', 'chmod', '+wr', importfile], capture_output=True)
    elif importfile and DRY_RUN:
        print(f"[DRY-RUN] Would run: sudo chmod +wr {importfile}")

    # Validate import file (skip validation in dry-run if we just exported)
    skip_validation = DRY_RUN and exported_from_pimcore
    if not skip_validation and not validate_import_file(importfile):
        print("INVALID FILENAME or UNREADABLE")
        rebuild = input("Unknown or No import file provided, <BREAK> to exit or <RETURN> for REBUILD: ").strip()
        if not rebuild:
            rebuild = 'y'

        if rebuild.lower() == 'y':
            print("Bypassing Import of new inventory parts")
        else:
            sys.exit(1)
    else:
        # Process the import file
        print(f"Processing {importfile}...")

        if not clean_import_file(importfile):
            print("IMPORT FILE NOT FOUND")
            sys.exit(1)

        # Run FilePro import
        run_import()
        print("IMPORT PROCESS COMPLETE")

    # Change to html directory for any post-processing
    if DRY_RUN:
        print("[DRY-RUN] Would change to: /appl/fileprow/html")
    elif os.path.isdir("/appl/fileprow/html"):
        os.chdir("/appl/fileprow/html")

    # Archive old TSV files, keeping 5 most recent
    archive_old_tsv_files()

    print("""

stimport complete.
""")

if __name__ == "__main__":
    main()
# ============================================================================
# End of stimport — Version: 1.3.1
# ============================================================================
